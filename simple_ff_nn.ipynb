{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import autograd\n",
    "from torch.utils import data\n",
    "from torch.backends import cudnn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HYPERPARAMETER & CONFIGURATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "max_epochs = 10\n",
    "n_batches = 42\n",
    "batch_size = 800\n",
    "\n",
    "params = {'batch_size': 6,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 6}\n",
    "max_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PRINTING DIGITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRINTING HANDLING HERE\n",
    "def print_digit(image):\n",
    "    # digits_train.head()\n",
    "    image = image.view(28, 28)\n",
    "    plt.figure(1, figsize=(3, 3))\n",
    "    plt.imshow(image.numpy(), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()\n",
    "    \n",
    "def random_digit(X, y):\n",
    "    x = rd.randint(0, X[:,0].shape[0])\n",
    "    \n",
    "    print_digit(X[x,:])\n",
    "    print(y[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATASET CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, list_IDs, labels):\n",
    "        'Initialization'\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        ID = self.list_IDs[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        X = torch.load('data/' + ID + '.pt')\n",
    "        y = self.labels[ID]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NEURAL NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "digits_train = pd.read_csv('data/train.csv')\n",
    "digits_submission = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42000"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(digits_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "partition = # IDs\n",
    "labels = # Labels\n",
    "\n",
    "# Generators\n",
    "training_set = Dataset(partition['train'], labels)\n",
    "training_generator = data.DataLoader(training_set, **params)\n",
    "\n",
    "validation_set = Dataset(partition['validation'], labels)\n",
    "validation_generator = data.DataLoader(validation_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over epochs\n",
    "for epoch in range(max_epochs):\n",
    "    # Training\n",
    "    for local_batch, local_labels in training_generator:\n",
    "        # Transfer to GPU\n",
    "        local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "\n",
    "        # Model computations\n",
    "        [...]\n",
    "\n",
    "    # Validation\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for local_batch, local_labels in validation_generator:\n",
    "            # Transfer to GPU\n",
    "            local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "\n",
    "            # Model computations\n",
    "            [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n",
      "(28000, 784)\n",
      "1    4684\n",
      "7    4401\n",
      "3    4351\n",
      "9    4188\n",
      "2    4177\n",
      "6    4137\n",
      "0    4132\n",
      "4    4072\n",
      "8    4063\n",
      "5    3795\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# data overview\n",
    "print(digits_train.shape)\n",
    "print(digits_submission.shape)\n",
    "print(digits_train.loc[:,'label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns ((n_samples, pixels), n_sample)\n",
    "def preprocess_labeled_data_into_tensors(df, label='label'):\n",
    "    train_tensor = torch.tensor(df.drop(label, axis=1).to_numpy(), dtype=torch.float)\n",
    "    labels_tensor = torch.tensor(df[label].to_numpy()) \n",
    "    \n",
    "    return train_tensor, labels_tensor\n",
    "\n",
    "# Returns ((n_samples, pixels), n_sample)\n",
    "def preprocess_unlabeled_data_into_tensor(df):\n",
    "    test = torch.tensor(df.to_numpy())\n",
    "    \n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEURAL NETWORK IMPLEMENTATION\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # three layers, input -> 250 -> 250 -> 10\n",
    "        self.linear1 = nn.Linear(784, 250)\n",
    "        self.linear2 = nn.Linear(250, 250)\n",
    "        self.linear3 = nn.Linear(250, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         print(x.shape)\n",
    "        # activation functions between layers\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "#         print(x.shape)\n",
    "        return F.log_softmax(x, dim=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data: nr_batches x (data, target)\n",
    "# data : tensor (elements_in_batch, 28, 28)\n",
    "# target : tensor (elements_in_batch, 1)\n",
    "def batch_data(X, y):\n",
    "    training = []\n",
    "\n",
    "    for i in range(n_batches):\n",
    "        # Local batches and labels\n",
    "        local_X, local_y = X_train[i * batch_size : (i + 1) * batch_size, ], y_train[i * batch_size : (i + 1) * batch_size, ]\n",
    "        training.append((local_X, local_y))\n",
    "        \n",
    "    return training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(training_data):\n",
    "    for epoch in range(max_epochs):\n",
    "        # training data: nr_batches x (data, target)\n",
    "        # data : tensor (elements_in_batch, 28, 28) NOPE\n",
    "        # target : tensor (elements_in_batch, 1)\n",
    "        for batch_idx, (data, target) in enumerate(training_data):\n",
    "            data, target = autograd.Variable(data), autograd.Variable(target)            \n",
    "            # resize data from (batch_size, 1, 28, 28) to (batch_size, 28*28)\n",
    "            # data = data.view(-1, 28*28)\n",
    "            print(data.shape)\n",
    "            # zero gradients to prevent accumulation\n",
    "            optimizer.zero_grad()\n",
    "            # nn output\n",
    "            # nSamples * nChannels? * nPixels\n",
    "            \n",
    "            # input = torch.randn(1, 784)\n",
    "            # out = net(input)\n",
    "            # print(out)\n",
    "            # print(out.shape)\n",
    "            print(data.shape)\n",
    "            net_out = net(data)\n",
    "            # get loss\n",
    "            loss = criterion(net_out, target)\n",
    "            # backpropagate\n",
    "            loss.backward()\n",
    "            # optimization step\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        epoch, batch_idx * len(data), len(training_data.dataset),\n",
    "                               100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "                \n",
    "# train_nn(train_batched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (linear1): Linear(in_features=784, out_features=250, bias=True)\n",
      "  (linear2): Linear(in_features=250, out_features=250, bias=True)\n",
      "  (linear3): Linear(in_features=250, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# create NNet instance and initialize optimizer and criterion\n",
    "net = Net()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "criterion = nn.NLLLoss()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = list(net.parameters())\n",
    "# print(len(params))\n",
    "# print(net.parameters())\n",
    "# print(params[0].size())  # conv1's .weight\n",
    "\n",
    "# # nSamples * nChannels? * nPixels\n",
    "# input = torch.randn(1, 784)\n",
    "# out = net(input)\n",
    "# print(out)\n",
    "# print(out.shape)\n",
    "\n",
    "# net.zero_grad()\n",
    "# out.backward(torch.randn(1, 10))\n",
    "\n",
    "# output = net(input)\n",
    "# target = torch.randn(10)  # a dummy target, for example\n",
    "# target = target.view(1, -1)  # make it the same shape as output\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "# loss = criterion(output, target)\n",
    "# print(loss)\n",
    "\n",
    "# print(loss.grad_fn)  # MSELoss\n",
    "# print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "# print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU\n",
    "\n",
    "# net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "# print('conv1.bias.grad before backward')\n",
    "# print(net.linear1.bias.grad)\n",
    "\n",
    "# loss.backward()\n",
    "\n",
    "# print('conv1.bias.grad after backward')\n",
    "# print(net.linear1.bias.grad)\n",
    "# print(net.linear1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([42000, 784])\n",
      "torch.Size([42000])\n"
     ]
    }
   ],
   "source": [
    "X, y = preprocess_labeled_data_into_tensors(digits_train)    \n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 784])\n",
      "torch.Size([800])\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "# partition data\n",
    "X_train, X_test,y_train,y_test = train_test_split(X, y, test_size=0.2)\n",
    "train_batched = batch_data(X_train, y_train)\n",
    "print(train_batched[0][0].shape)\n",
    "print(train_batched[0][1].shape)\n",
    "print(len(train_batched))\n",
    "# train_nn(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 784])\n",
      "torch.Size([800, 784])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-0dc7883cab55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batched\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-95-7ac7c63e0f21>\u001b[0m in \u001b[0;36mtrain_nn\u001b[0;34m(training_data)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n\u001b[0;32m---> 31\u001b[0;31m                         \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                                100. * batch_idx / len(train_loader), loss.data[0]))\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'dataset'"
     ]
    }
   ],
   "source": [
    "train_nn(train_batched)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
